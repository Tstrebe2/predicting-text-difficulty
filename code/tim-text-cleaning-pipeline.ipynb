{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tstrebe2/predicting-text-difficulty/blob/dave-updates/code/tim-text-cleaning-pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "!{sys.executable} -m pip install pyspark==3.1.2 -q\n",
        "!{sys.executable} -m pip install spark-nlp==4.2.0 -q\n",
        "# !{sys.executable} -m pip install transformers==4.22.2 -q\n",
        "# !{sys.executable} -m pip install -U spacy==3.4.1 -q\n",
        "\n",
        "# !{sys.executable} -m spacy download en_core_web_lg -q"
      ],
      "metadata": {
        "id": "R6Z4jjikrL1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# !wget https://raw.githubusercontent.com/Tstrebe2/predicting-text-difficulty/main/assets/WikiLarge_Train.csv -q\n",
        "# !wget https://raw.githubusercontent.com/mahavivo/vocabulary/master/lemmas/AntBNC_lemmas_ver_001.txt -q\n",
        "# !wget https://raw.githubusercontent.com/Tstrebe2/predicting-text-difficulty/main/assets/dale_chall.txt -q\n",
        "# !wget https://raw.githubusercontent.com/Tstrebe2/predicting-text-difficulty/main/assets/AoA_51715_words.csv -q\n",
        "# !wget https://raw.githubusercontent.com/Tstrebe2/predicting-text-difficulty/main/assets/Concreteness_ratings_Brysbaert_et_al_BRM.txt -q\n",
        "# !wget https://github.com/allenai/spv2/blob/master/model/glove.6B.100d.txt.gz -q\n",
        "# !wget http://nlp.stanford.edu/data/glove.6B.zip -q\n",
        "!unzip glove*.zip"
      ],
      "metadata": {
        "id": "yY036731rSpx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a648c72-5544-4ed7-e374-a4ecd9a3c398"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "replace glove.6B.100d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "aoa = pd.read_csv('/content/AoA_51715_words.csv', \n",
        "                     encoding_errors='ignore', \n",
        "                     usecols=['Lemma_highest_PoS', 'AoA_Kup_lem'],\n",
        "                     ).rename({'Lemma_highest_PoS':'lemma', 'AoA_Kup_lem':'aoa'}, axis=1)\n",
        "\n",
        "aoa = aoa.groupby('lemma').first().to_dict()['aoa']\n",
        "\n",
        "conc = (pd.read_csv('/content/Concreteness_ratings_Brysbaert_et_al_BRM.txt', \n",
        "                   sep='\\t',\n",
        "                   usecols=['Word', 'Bigram', 'Conc.M'])\n",
        "        .rename({'Word':'word', 'Bigram':'bigram', 'Conc.M':'conc_mean'}, axis=1))\n",
        "\n",
        "def split_word(x):\n",
        "  if x['bigram'] == 0:\n",
        "    word_or_phrase = x['word']\n",
        "  else:\n",
        "    word_or_phrase = tuple(x['word'].split(' '))\n",
        "\n",
        "  return {'word':word_or_phrase, 'conc_mean':x['conc_mean'] }\n",
        "\n",
        "conc = conc.apply(split_word, axis=1, result_type='expand').set_index('word').to_dict()['conc_mean']\n",
        "\n",
        "d_chall = set(pd.read_csv('/content/dale_chall.txt', names=['word'])['word'].tolist())"
      ],
      "metadata": {
        "id": "WnpcW0-uqlvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StringType\n",
        "from pyspark.ml import Pipeline\n",
        "import pyspark.sql.functions as F\n",
        "from sparknlp.base import DocumentAssembler, EmbeddingsFinisher\n",
        "from sparknlp.annotator import SentenceDetector, Tokenizer, Normalizer, Lemmatizer, WordEmbeddingsModel, StopWordsCleaner\n",
        "import sparknlp\n",
        "from pyspark.sql.types import StringType, ArrayType, FloatType, StructType\n",
        "import numpy as np\n",
        "import string\n",
        "\n",
        "spark = SparkSession.builder\\\n",
        "        .master(\"local\")\\\n",
        "        .appName(\"Colab\")\\\n",
        "        .config('spark.ui.port', '4050')\\\n",
        "        .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:4.2.0\")\\\n",
        "        .getOrCreate()\n",
        "\n",
        "df = spark.read.csv('/content/WikiLarge_Train.csv', header=True)\n",
        "df.createOrReplaceTempView('wiki')\n",
        "\n",
        "regex1, replace1 = r'-LRB-', '('\n",
        "regex2, replace2 = r'-RRB-', ')'\n",
        "regex3, replace3 = r\"\\'\\' *\", ''\n",
        "regex4, replace4 = r\", ; *\", ''\n",
        "regex5, replace5 = r\"; , *\", ''\n",
        "regex6, replace6 = r\", , *\", ''\n",
        "regex7, replace7 = r\"; ; *\", ''\n",
        "regex8, replace8 = r\"[(] [;,-]* [)] \", ''\n",
        "regex9, replace9 = r\"[(] +[)] *\", ''\n",
        "regex10, replace10 = r\" km \", \"kilometers\"\n",
        "regex11, replace11 = r\"[0-9]+(km) \", \"kilometers\"\n",
        "regex12, replace12 = r\" mph \",\" miles per hour \"\n",
        "regex13, replace13 = r\"° C \",\"degrees Celsius\"\n",
        "regex14, replace14 = r\"° F \",\"degrees Farenheit\"\n",
        "regex15, replace15 = r\"°\",\"degrees\"\n",
        "regex16, replace16 = r\" %\",\" percent\"\n",
        "regex17, replace17 = r\" cm\",\" centimeters\"\n",
        "regex18, replace18 = r\" kg \",\" kilograms \"\n",
        "\n",
        "iterable = ((regex1, replace1), (regex2, replace2), (regex3, replace3),\n",
        "            (regex4, replace4), (regex5, replace5), (regex6, replace6),\n",
        "            (regex7, replace7), (regex8, replace8), (regex9, replace9),\n",
        "            (regex10,replace10), (regex11,replace11),(regex12, replace12),\n",
        "            (regex13, replace13),(regex14,replace14),(regex15,replace15),\n",
        "            (regex16,replace16), (regex17,replace17),(regex18,replace18))\n",
        "\n",
        "for regex, replace in iterable:\n",
        "  query = f\"\"\"\n",
        "  SELECT\n",
        "    regexp_replace(original_text, '{regex}', '{replace}') as original_text, \n",
        "    label \n",
        "  FROM wiki;\"\"\"\n",
        "  df = spark.sql(query)\n",
        "  df.createOrReplaceTempView('wiki')\n",
        "\n",
        "query = r\"SELECT * FROM wiki WHERE LENGTH(original_text) > 20;\"\n",
        "df = spark.sql(query)\n",
        "df.createOrReplaceTempView('wiki')\n",
        "\n",
        "documentAssembler = DocumentAssembler()\\\n",
        "    .setInputCol(\"original_text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "tokenizer = Tokenizer() \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"token\")\n",
        "\n",
        "lemmatizer = Lemmatizer() \\\n",
        "    .setInputCols([\"token\"]) \\\n",
        "    .setOutputCol(\"lemma\") \\\n",
        "    .setDictionary(\"./AntBNC_lemmas_ver_001.txt\", value_delimiter =\"\\t\", key_delimiter = \"->\")\n",
        "\n",
        "nlp_pipeline = Pipeline(stages=[documentAssembler,\n",
        "                                tokenizer,\n",
        "                                lemmatizer,\n",
        "                               ])\n",
        "\n",
        "nlp_pipeline = nlp_pipeline.fit(df)\n",
        "df = nlp_pipeline.transform(df)\n",
        "df.createOrReplaceTempView('wiki')\n",
        "\n",
        "def get_d_chall(x):\n",
        "  easy_count = 0\n",
        "  word_count = 0\n",
        "\n",
        "  for token in x:\n",
        "    if token in string.punctuation:\n",
        "      continue\n",
        "\n",
        "    token_lower = token.lower()\n",
        "\n",
        "    if token_lower in d_chall:\n",
        "      easy_count += 1\n",
        "\n",
        "    word_count += 1\n",
        "\n",
        "  difficult_count = (word_count-easy_count)\n",
        "\n",
        "  return (0.1579 * ((difficult_count/word_count) * 100) + 0.0496 * word_count\n",
        "          if word_count else 0.0)\n",
        "\n",
        "\n",
        "def get_aoa(x):\n",
        "  arr = [aoa[w.lower()] for w in x if w.lower() in aoa]\n",
        "  if len(arr) > 0:\n",
        "    return arr\n",
        "  else:\n",
        "    return [0.0] \n",
        "\n",
        "def get_conc_rating(x):\n",
        "  ret_val = []\n",
        "\n",
        "  bigrams = [(f.lower(), s.lower()) for f, s in zip(x[:-1], x[1:])]\n",
        "  cont = False\n",
        "  \n",
        "  for bigram in bigrams:\n",
        "    if cont:\n",
        "      cont = False\n",
        "      continue\n",
        "\n",
        "    if bigram in conc:\n",
        "      cont = True\n",
        "      ret_val.append(conc[bigram])\n",
        "    elif bigram[0] in conc:\n",
        "      ret_val.append(conc[bigram[0]])\n",
        "\n",
        "  return ret_val\n",
        "\n",
        "def get_num_lemmas(x):\n",
        "  num_lemmas = 0.0\n",
        "\n",
        "  for token in x:\n",
        "    if token not in string.punctuation:\n",
        "      num_lemmas += 1.0\n",
        "\n",
        "  return num_lemmas\n",
        "    \n",
        "spark.udf.register('get_d_chall', get_d_chall, FloatType())\n",
        "spark.udf.register('get_aoa', get_aoa, ArrayType(FloatType()))\n",
        "spark.udf.register('get_conc_rating', get_conc_rating, ArrayType(FloatType()))\n",
        "spark.udf.register('get_num_lemmas', get_num_lemmas, FloatType())\n",
        "spark.udf.register('get_joined_text', lambda x: ' '.join(x), StringType())\n",
        "spark.udf.register('array_mean', lambda x: float(np.mean(x)), FloatType())\n",
        "\n",
        "query = r\"\"\"\n",
        "SELECT \n",
        "  original_text, \n",
        "  get_joined_text(lemma.result) as lemmatized_text, \n",
        "  get_d_chall(lemma.result) as d_chall_score,\n",
        "  get_aoa(lemma.result) as aoa,\n",
        "  get_conc_rating(lemma.result) as conc_rating,\n",
        "  get_num_lemmas(lemma.result) as num_lemmas,\n",
        "  label\n",
        "FROM wiki;\n",
        "\"\"\"\n",
        "df = spark.sql(query)\n",
        "df.createOrReplaceTempView('wiki')\n",
        "\n",
        "spark.udf.register('array_mean', lambda x: float(np.mean(x)), FloatType())\n",
        "\n",
        "query = r\"\"\"\n",
        "SELECT \n",
        "original_text, \n",
        "lemmatized_text,\n",
        "d_chall_score,\n",
        "array_mean(aoa) as aoa_mean, \n",
        "array_min(aoa) as aoa_min, \n",
        "array_max(aoa) as aoa_max, \n",
        "array_mean(conc_rating) as conc_rating_mean, \n",
        "array_min(conc_rating) as conc_rating_min, \n",
        "array_max(conc_rating) as conc_rating_max,\n",
        "num_lemmas,\n",
        "label\n",
        "FROM wiki; \n",
        "\"\"\"\n",
        "df = spark.sql(query)\n",
        "df.createOrReplaceTempView('wiki')\n",
        "df.show(5, 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6XQTiVA_yjo",
        "outputId": "8738a29d-7f8d-4d8b-a2e4-96ff7936ca44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------+---------+-------+-------+----------------+---------------+---------------+----------+-----+\n",
            "|original_text                                                                                                                                                                                                                                         |lemmatized_text                                                                                                                                                                                                                 |d_chall_score|aoa_mean |aoa_min|aoa_max|conc_rating_mean|conc_rating_min|conc_rating_max|num_lemmas|label|\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------+---------+-------+-------+----------------+---------------+---------------+----------+-----+\n",
            "|There is manuscript evidence that Austen continued to work on these pieces as late as the period 1809 â 11 , and that her niece and nephew , Anna and James Edward Austen , made further additions as late as 1814 .                                  |There be manuscript evidence that Austen continue to work on these piece as late as the period 1809 â 11 , and that she niece and nephew , Anna and James Edward Austen , make far addition as late as 1814 .                   |8.533221     |5.8093104|3.57   |12.12  |2.4955173       |1.33           |4.57           |38.0      |1    |\n",
            "|In a remarkable comparative analysis , Mandaean scholar Säve-Söderberg demonstrated that Mani 's Psalms of Thomas were closely related to Mandaean texts .                                                                                            |In a remarkable comparative analysis , Mandaean scholar Säve-Söderberg demonstrate that Mani ' s Psalms of Thomas be closely relate to Mandaean text .                                                                          |12.320171    |7.4023075|2.89   |11.94  |2.3342857       |1.46           |4.93           |21.0      |1    |\n",
            "|Before Persephone was released to Hermes , who had been sent to retrieve her , Hades tricked her into eating pomegranate seeds , ( six or three according to the telling ) which forced her to return to the underworld for a period each year .      |Before Persephone be release to Hermes , who have be send to retrieve she , Hades trick she into eat pomegranate seed , ( six or three accord to the tell ) which force she to return to the underworld for a period each year .|5.9315       |5.2313514|2.78   |11.17  |2.5564864       |1.43           |4.86           |40.0      |1    |\n",
            "|Cogeneration plants are commonly found in district heating systems of cities , hospitals , prisons , oil refineries , paper mills , wastewater treatment plants , thermal enhanced oil recovery wells and industrial plants with large heating needs .|Cogeneration plant be commonly find in district heat system of city , hospital , prison , oil refinery , paper mill , wastewater treatment plant , thermal enhance oil recovery well and industrial plant with large heat need .|7.0150123    |6.742    |3.56   |11.53  |3.3696551       |1.52           |4.93           |32.0      |1    |\n",
            "|Geneva is the second-most-populous city in Switzerland ( after Zürich ) and is the most populous city of Romandie ( the French-speaking part of Switzerland ) .                                                                                       |Geneva be the second-most-populous city in Switzerland ( after Zürich ) and be the most populous city of Romandie ( the French-speaking part of Switzerland ) .                                                                 |7.5507455    |5.455    |3.69   |12.62  |2.3993332       |1.43           |4.79           |22.0      |1    |\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------+---------+-------+-------+----------------+---------------+---------------+----------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.toPandas()"
      ],
      "metadata": {
        "id": "6ly4NBM_sqm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://edumunozsala.github.io/BlogEms/jupyter/nlp/classification/embeddings/python/2020/08/15/Intro_NLP_WordEmbeddings_Classification.html\n",
        "# https://radimrehurek.com/gensim_3.8.3/models/keyedvectors.html\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "root_path = '/content/'\n",
        "glove_file_name = 'glove.6B.100d.txt'\n",
        "glove_path = ''.join([root_path, glove_file_name])\n",
        "\n",
        "word2vec_output_file = ''.join([glove_file_name, '.word2vec'])\n",
        "glove2word2vec(glove_path, word2vec_output_file)\n",
        "\n",
        "model = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)\n",
        "\n",
        "def get_sentence_embedding(sent):\n",
        "  sentence_embedding = np.zeros((0, 100))\n",
        "  tokens = sent.split(' ')\n",
        "  \n",
        "  for token in tokens:\n",
        "    token_lower = token.lower()\n",
        "\n",
        "    if token_lower in model:\n",
        "      word_vector = model.get_vector(token_lower)\n",
        "      sentence_embedding = np.vstack((sentence_embedding, word_vector))\n",
        "\n",
        "  if sentence_embedding.shape[0] == 0:\n",
        "    return np.zeros(100)\n",
        "  else:\n",
        "    return sentence_embedding.mean(axis=0)"
      ],
      "metadata": {
        "id": "8KLwE8Vzlzg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = np.array(df['original_text'].apply(get_sentence_embedding).tolist())\n",
        "embeddings.shape"
      ],
      "metadata": {
        "id": "dE8o2AwO5zpV",
        "outputId": "507ec776-a7bf-4d5f-e05b-1268e820a7e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(395169, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "y = df['label'].astype(np.int64)\n",
        "X_train, X_test, y_train, y_test = train_test_split(embeddings, y, test_size=.1, random_state=99)\n",
        "\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "id": "ENONlbJiswJ_",
        "outputId": "d962bd79-d261-4755-8396-971e6f937d0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((355652, 100), (39517, 100), (355652,), (39517,))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import make_pipeline \n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "clf = make_pipeline(StandardScaler(), LogisticRegression(n_jobs=-1)).fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "U7wO3MqutVeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "y_hat = clf.predict(X_test)\n",
        "y_proba = clf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "roc_auc = roc_auc_score(y_test, y_proba)\n",
        "accuracy = accuracy_score(y_test, y_hat)\n",
        "f1 = f1_score(y_test, y_hat)\n",
        "\n",
        "print('ROC AUC:', roc_auc)\n",
        "print('Accuracy:', accuracy)\n",
        "print('F1:', f1)"
      ],
      "metadata": {
        "id": "MeSOHK0Mtrui",
        "outputId": "2307a06c-3cf8-4df6-b271-8753115c1b23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC AUC: 0.6662212002745456\n",
            "Accuracy: 0.6354986461522889\n",
            "F1: 0.6687669594812123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df[['lemmatized_text']], y, test_size=.1, random_state=99)\n",
        "\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "id": "pdTfICT3LO6X",
        "outputId": "c7c3192a-4374-427e-b6cd-15bfe931322f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((355652, 1), (39517, 1), (355652,), (39517,))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "clf = make_pipeline(TfidfVectorizer(min_df=25, stop_words='english'), \n",
        "                    LogisticRegression(n_jobs=-1)).fit(X_train['lemmatized_text'], y_train)"
      ],
      "metadata": {
        "id": "x8gX0SbZK64W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat = clf.predict(X_test['lemmatized_text'])\n",
        "y_proba = clf.predict_proba(X_test['lemmatized_text'])[:, 1]\n",
        "\n",
        "roc_auc = roc_auc_score(y_test, y_proba)\n",
        "accuracy = accuracy_score(y_test, y_hat)\n",
        "f1 = f1_score(y_test, y_hat)\n",
        "\n",
        "print('ROC AUC:', roc_auc)\n",
        "print('Accuracy:', accuracy)\n",
        "print('F1:', f1)"
      ],
      "metadata": {
        "id": "_kmPOhfSLiA-",
        "outputId": "9cd07113-f6e6-42be-fe81-2b4ee937369d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC AUC: 0.730130701783159\n",
            "Accuracy: 0.6654098236202141\n",
            "F1: 0.6759631408685423\n"
          ]
        }
      ]
    }
  ]
}